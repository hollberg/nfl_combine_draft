{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# personal module scripts\n",
    "import clean_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean NFL Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combine_file = r'data\\nfl_combine_1987_2020.csv'\n",
    "\n",
    "df_raw_combine = pd.read_csv(combine_file)\n",
    "\n",
    "df_raw_combine.head()\n",
    "\n",
    "# Keep raw data import for reference - build copy to modify\n",
    "df_combine = df_raw_combine\n",
    "\n",
    "# Drop dummy '0' column and Wonderlic scores data\n",
    "combine_cols_to_drop = ['Unnamed: 0', 'Wonderlic']\n",
    "df_combine.drop(columns=combine_cols_to_drop, inplace=True)\n",
    "\n",
    "# Clean column headers\n",
    "df_combine.columns = df_combine.columns.str.lower()\n",
    "df_combine.rename(columns={'college':'school'}, inplace=True)\n",
    "\n",
    "# Clean school names\n",
    "df_combine['school'] = df_combine['school'].str.strip()\n",
    "\n",
    "# Drop years prior to 2000 (no draft data)\n",
    "print(df_combine.shape)\n",
    "df_combine.drop(df_combine[df_combine['year']<2000].index, inplace=True)\n",
    "print('Cleaned combine size: ', df_combine.shape)\n",
    "df_combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import position mapping data\n",
    "The \"combine\" dataset maps players to very specific positions (ie, \"Free Safety\" or \"Outside Linebacker\").\n",
    "\n",
    "Map these granular positions to more standard positions. Also classify each position as \"Offense\" or \"Defense\", and indicate if the position is a \"Skill\" position or on the line of scrimmage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_positions = pd.read_csv('data/position_mapping.csv')\n",
    "df_positions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the draft and position mapping datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Granular position counts in combine dataset:')\n",
    "print(df_combine['pos'].value_counts().head())\n",
    "\n",
    "df_combine = df_combine.merge(df_positions,\n",
    "                          how='left',\n",
    "                          on='pos')\n",
    "\n",
    "print('\\nPosition Group counts after merging with position map:')\n",
    "print(df_combine['pos_group'].value_counts())\n",
    "\n",
    "df_combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Visualize combine performance distributions by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positions = df_combine['pos_group'].unique()\n",
    "\n",
    "positions_to_drop = ['SN', 'K']   # Long snappers and kickers/punters\n",
    "\n",
    "positions = [pos for pos in positions if pos not in positions_to_drop]\n",
    "print(positions)\n",
    "\n",
    "# Sort positions by L(ine)/S(kill)\n",
    "sort_dict = pd.Series(df_positions['line_or_skill'].values,index=df_positions['pos_group']).to_dict()\n",
    "print(sort_dict)\n",
    "positions.sort(key=lambda x: sort_dict[x])\n",
    "print(positions)\n",
    "\n",
    "print('Unique Positions: ', len(positions))\n",
    "print(df_combine.columns)\n",
    "stat_columns = ['height (in)', 'weight (lbs)',\n",
    "       'hand size (in)', 'arm length (in)', '40 yard', 'bench press',\n",
    "       'vert leap (in)', 'broad jump (in)', 'shuttle', '3cone', '60yd shuttle']\n",
    "num_stats = len(stat_columns)\n",
    "\n",
    "fig, axes = plt.subplots(len(positions), num_stats,\n",
    "                         sharex=False,\n",
    "                         sharey=True,\n",
    "                         figsize=(25,25))\n",
    "\n",
    "fig.suptitle('NFL Combine Statistics - Distribution by Position (2000-2020)', fontsize=30)\n",
    "fig.supxlabel('Measurement', fontsize=30)\n",
    "fig.supylabel('Position', fontsize=30)\n",
    "\n",
    "fig.tight_layout(rect=[0.03, 0.03, 1, .95])\n",
    "\n",
    "# Loop over axes and data\n",
    "for row, pos in enumerate(positions):\n",
    "    x_positions = df_combine[df_combine['pos_group']==pos]\n",
    "\n",
    "    for col, stat in enumerate(stat_columns):\n",
    "        # Get axis\n",
    "        ax = axes[row,col]\n",
    "        x = x_positions[stat]\n",
    "        ax.hist(x,\n",
    "                range=[df_combine[stat].min(),df_combine[stat].max()],\n",
    "                alpha=.5, bins=10)\n",
    "        # Set Y label once per row\n",
    "        if col==0:\n",
    "            ax.set_ylabel(pos, fontsize='xx-large')\n",
    "\n",
    "        # Set X label above first row and below last row\n",
    "        if row == 0:\n",
    "            ax.set_title(stat, fontsize='xx-large')\n",
    "        if row == len(positions) - 1:\n",
    "            ax.set_xlabel(stat, fontsize='xx-large')\n",
    "\n",
    "fig.show()\n",
    "fig.savefig('images/stats_by_position.png', format='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and clean NFL Draft Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draft_file = r'data\\espn_draft_history_2000_2021_cleaned.csv'\n",
    "df_raw_draft = pd.read_csv(draft_file)\n",
    "\n",
    "# Keep raw data import for reference - build copy to modify\n",
    "df_draft = df_raw_draft\n",
    "\n",
    "# Clean column headers\n",
    "df_draft.columns = df_draft.columns.str.lower()\n",
    "\n",
    "# Clean school names\n",
    "df_draft['school'] = df_draft['school'].str.strip()\n",
    "df_draft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there duplicated names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_combine['name'].value_counts(sort='descending').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: Yes\n",
    "\n",
    "So we cannot simply join the 2 datasets on player 'name' columns. Need to also join on\n",
    "college and year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do college names match in both datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draft_school = pd.DataFrame(df_draft['school'].unique()).rename(columns={0:'school'})\n",
    "draft_school['source'] = 'draft'\n",
    "combine_school = pd.DataFrame(df_combine['school'].unique()).rename(columns={0:'school'})\n",
    "combine_school['source'] = 'combine'\n",
    "print(type(combine_school))\n",
    "print(combine_school.head())\n",
    "\n",
    "schools = draft_school.merge(combine_school, on='school', how='outer',\n",
    "                             suffixes=['_draft', '_combine']).sort_values(by='school')\n",
    "\n",
    "# List all cases with mismatches\n",
    "na_mask = schools.isna().any(axis=1)\n",
    "schools[na_mask].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### So we see that the 'combine' dataset frequently has the state appended to the school name;\n",
    "Ex: \"Abilene Christian (TX)\". Remove these from school names, with the exception of \"Miami (OH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_combine['school'] = df_combine['school'].str.replace('Miami (OH)', 'Miami - OH')\n",
    "\n",
    "print(df_combine['school'].head())\n",
    "regex_replace_parens = r'\\([^)]*[a-zA-Z][^)]*\\)'\n",
    "df_combine['school'] = df_combine['school'].str.replace(regex_replace_parens,\n",
    "                                                        '', regex=True)\n",
    "\n",
    "df_combine['school'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize player names between datasets\n",
    "Player names in the \"Draft\" dataset include suffixes including \"Jr., II, III, IV\", but these are NOT included in the \"combine\" dataset.\n",
    "\n",
    "Standardize player names between datasets by removing these values from the \"Draft\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "regex_suffixes_to_remove = r'Jr\\.$|III$|IIII$|IV$|, Jr.$'\n",
    "df_draft['name'] = df_draft['name'].str.replace(regex_suffixes_to_remove,\n",
    "                                                '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the Draft and NFL Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_merged = df_combine.merge(df_draft, how='left',\n",
    "                             on=['name', 'school', 'year'])\n",
    "\n",
    "df_merged.head()\n",
    "\n",
    "# df_merged.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Investigate merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning:\n",
    "* Very few 60-yard shuttle records; drop column\n",
    "* Drop all undrafted players - will only focus on drafted players\n",
    "* Drop kickers, long snappers, QBs and Fullbacks (too few, draft status not driven by stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop 60yd shuttle (too few data points), duplicative columns related to\n",
    "# player position, and things like year and team name\n",
    "merged_cols_to_drop = ['year', 'name', 'school', 'pos',\n",
    "                       '60yd shuttle',\n",
    "                       'pk(ovr)', 'team', 'position']\n",
    "\n",
    "try:\n",
    "    df_merged.drop(columns=merged_cols_to_drop, inplace=True)\n",
    "except:\n",
    "    print('Issue dropping columns')\n",
    "\n",
    "\n",
    "# overwite blank 'round' values with '8' (will indicate undrafted)\n",
    "# df_merged['round'].fillna(8, inplace=True)\n",
    "df_merged.dropna(inplace=True)\n",
    "\n",
    "# df_merged['round'].loc[(df_merged['round']>=1) & (df_merged['round']<4)] = 1\n",
    "# df_merged['round'].loc[(df_merged['round']>=4) & (df_merged['round']<8)] = 2\n",
    "# df_merged['round'].fillna(3, inplace=True)\n",
    "# print(df_merged['round'].value_counts())\n",
    "\n",
    "print('\\n Remaining Columns')\n",
    "print(df_merged.columns)\n",
    "\n",
    "positions_to_drop = ['SN', 'K', 'QB', 'FB']\n",
    "positions_mask = \\\n",
    "    df_merged[df_merged['pos_group'].isin(positions_to_drop)].index\n",
    "\n",
    "print(positions_mask)\n",
    "\n",
    "print(df_merged.shape)\n",
    "df_merged.drop(positions_mask, inplace=True)\n",
    "print(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop players with sparse combine statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics_cols = ['height (in)', 'weight (lbs)', 'hand size (in)', 'arm length (in)',\n",
    "       '40 yard', 'bench press', 'vert leap (in)', 'broad jump (in)',\n",
    "       'shuttle', '3cone']\n",
    "\n",
    "# See count of records by number of missing metrics values\n",
    "# 10 total metrics values, drop if they don't have at least 8\n",
    "print('\\n Missing metrics per row')\n",
    "print(df_merged[metrics_cols].isna().sum(axis=1).value_counts())\n",
    "df_merged.dropna(axis=0, thresh=7,\n",
    "                 subset=metrics_cols, inplace=True)\n",
    "print('\\nRemaining missing metrics by row')\n",
    "print(df_merged[metrics_cols].isna().sum(axis=1).value_counts())\n",
    "\n",
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Impute missing values based on average of players with same position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(df_merged.head(10))\n",
    "\n",
    "df_merged = clean_data.group_imputer(\n",
    "    df=df_merged,\n",
    "    grouping_col='pos_group',\n",
    "    cols_to_impute=metrics_cols)\n",
    "\n",
    "# print('\\n')\n",
    "# print(df_merged.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Drop either \"line\" or \"skill\" players from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop_skill_or_line = 'S'    # 'S' for skill or 'L' for line\n",
    "drop_index = df_merged[df_merged['line_or_skill']==drop_skill_or_line].index\n",
    "df_for_models = df_merged.drop(drop_index)\n",
    "df_for_models.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To visualize pipeline models\n",
    "from sklearn import set_config\n",
    "from sklearn.utils import estimator_html_repr\n",
    "\n",
    "\n",
    "# encoders\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Boosted Models\n",
    "# Use this one if you have an M1 chip.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Permutation Importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# for displaying images and html\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setup sklearn tools to visualize pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = 'round'\n",
    "X = df_for_models.drop(columns=target)\n",
    "y = df_for_models[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=.2,\n",
    "                                                    random_state=21)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape} X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "baseline = y.value_counts(normalize=True).max()\n",
    "baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree Classifier Model/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Base Model\n",
    "model_dt = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    DecisionTreeClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "print('Decision Tree Training Accuracy', model_dt.score(X_train, y_train))\n",
    "print('Decision Tree Validation Accuracy', model_dt.score(X_test, y_test))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=model_dt.predict(X_test))\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                                 display_labels=model_dt.classes_)\n",
    "display.plot()\n",
    "\n",
    "# Export HTML of pipeline model\n",
    "with open('pipe_html/model_dt.html', 'w') as f:\n",
    "    f.write(estimator_html_repr(model_dt))\n",
    "\n",
    "model_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build Tuned Random Forest Model/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Base Model\n",
    "model_rf = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    RandomForestClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "# Parameter distributions for hyperparameter tuning\n",
    "# Note double underscores __ in keys below\n",
    "param_distributions = {\n",
    "    'randomforestclassifier__max_depth': range(3,50,5),\n",
    "    'randomforestclassifier__n_estimators': range(10,2000, 10),\n",
    "    'randomforestclassifier__bootstrap': [True, False],\n",
    "    'randomforestclassifier__warm_start': [True, False]\n",
    "}\n",
    "\n",
    "tuned_rf = RandomizedSearchCV(\n",
    "    model_rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=25,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=6\n",
    ")\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "tuned_rf.fit(X_train, y_train)\n",
    "\n",
    "# Export HTML of pipeline model\n",
    "with open('pipe_html/tuned_rf.html', 'w') as f:\n",
    "    f.write(estimator_html_repr(tuned_rf))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=tuned_rf.predict(X_test))\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                                 display_labels=tuned_rf.classes_)\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Tuned Random Forest Model/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Tuned RF training best score: ', tuned_rf.best_score_)\n",
    "print('Tuned RF best parameters: ', tuned_rf.best_params_)\n",
    "print('Tuned RF test score: ', tuned_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get Permutation importances for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importances = model_rf.named_steps['randomforestclassifier'].feature_importances_\n",
    "\n",
    "gini_imp = pd.DataFrame(data=importances, index=X_test.columns, columns=['gini_impurity']).sort_values(by='gini_impurity')\n",
    "\n",
    "gini_imp.tail(10).plot(kind='barh');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build XGBoost Model/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_xgb = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    XGBClassifier(\n",
    "        loss='deviance',\n",
    "        # learning_rate=0.1,\n",
    "        n_estimators=500,\n",
    "        subsample=1,\n",
    "        max_depth=4,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Export HTML of pipeline model\n",
    "with open('pipe_html/model_xgb.html', 'w') as f:\n",
    "    f.write(estimator_html_repr(model_xgb))\n",
    "\n",
    "model_xgb\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=model_xgb.predict(X_test))\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                                 display_labels=model_xgb.classes_)\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate XGBoost Model/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('XGBoost Forest Training Accuracy', model_xgb.score(X_train, y_train))\n",
    "print('XGBoost Forest Validation Accuracy', model_xgb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Ridge Classifier Model/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_ridge = make_pipeline(\n",
    "    OneHotEncoder(),\n",
    "    RidgeClassifierCV(cv=5,\n",
    "                      alphas=[.1,1.0,10.0])\n",
    ")\n",
    "\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=model_ridge.predict(X_test))\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                                 display_labels=model_ridge.classes_)\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Ridge Classifier Model/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Ridge Classifier Training Accuracy', model_ridge.score(X_train, y_train))\n",
    "print('Ridge Classifier Validation Accuracy', model_ridge.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Tuned Ridge Classifier Model/Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Tuned Ridge Classifier Training Accuracy 0.25036603221083453\n",
      "Tuned Ridge Classifier Validation Accuracy 0.24561403508771928\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=5,\n                   estimator=Pipeline(steps=[('onehotencoder',\n                                              OneHotEncoder(cols=['pos_group',\n                                                                  'offense_defense',\n                                                                  'line_or_skill'])),\n                                             ('ridgeclassifiercv',\n                                              RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ])))]),\n                   n_jobs=6,\n                   param_distributions={'ridgeclassifiercv__class_weight': ['balanced',\n                                                                            None],\n                                        'ridgeclassifiercv__cv': range(2, 10),\n                                        'ridgeclassifiercv__fit_intercept': [True,\n                                                                             False]},\n                   verbose=1)",
      "text/html": "<style>#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa {color: black;background-color: white;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa pre{padding: 0;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-toggleable {background-color: white;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-estimator:hover {background-color: #d4ebff;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-item {z-index: 1;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-parallel-item:only-child::after {width: 0;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-dfff2316-b137-4ea4-97dd-c457b064b1fa div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-dfff2316-b137-4ea4-97dd-c457b064b1fa\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1415e646-64f2-4f01-aa44-5c44c81a2d33\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1415e646-64f2-4f01-aa44-5c44c81a2d33\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n                   estimator=Pipeline(steps=[('onehotencoder',\n                                              OneHotEncoder(cols=['pos_group',\n                                                                  'offense_defense',\n                                                                  'line_or_skill'])),\n                                             ('ridgeclassifiercv',\n                                              RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ])))]),\n                   n_jobs=6,\n                   param_distributions={'ridgeclassifiercv__class_weight': ['balanced',\n                                                                            None],\n                                        'ridgeclassifiercv__cv': range(2, 10),\n                                        'ridgeclassifiercv__fit_intercept': [True,\n                                                                             False]},\n                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f34ec37f-0ddf-48cb-b684-32dbcf624250\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f34ec37f-0ddf-48cb-b684-32dbcf624250\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(cols=['pos_group', 'offense_defense', 'line_or_skill'])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"05b0d1c5-7b70-49a3-b6f4-43877fe6314a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"05b0d1c5-7b70-49a3-b6f4-43877fe6314a\">RidgeClassifierCV</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]))</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Base Model\n",
    "model_ridgecv = make_pipeline(\n",
    "    OneHotEncoder(),\n",
    "    RidgeClassifierCV()\n",
    ")\n",
    "\n",
    "# Parameter distributions for hyperparameter tuning\n",
    "# Note double underscores __ in keys below\n",
    "param_distributions = {\n",
    "    'ridgeclassifiercv__cv': range(2, 10),\n",
    "    'ridgeclassifiercv__fit_intercept': [True, False],\n",
    "    'ridgeclassifiercv__class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "tuned_ridge = RandomizedSearchCV(\n",
    "    model_ridgecv,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=6\n",
    ")\n",
    "\n",
    "model_ridgecv.fit(X_train, y_train)\n",
    "tuned_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Tuned Ridge Classifier Training Accuracy', tuned_ridge.score(X_train, y_train))\n",
    "print('Tuned Ridge Classifier Validation Accuracy', tuned_ridge.score(X_test, y_test))\n",
    "\n",
    "tuned_ridge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (nfl_combine_draft)",
   "language": "python",
   "name": "pycharm-437d00df"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}